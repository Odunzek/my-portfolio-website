---
title: Designing an AI Solution Under Pressure: Lessons from an AI Hackathon
publishedAt: 2025-12-16T18:00:00.000Z
summary: A reflection on an AI hackathon where we were challenged to define a real problem, design an AI-powered solution on the spot, and build a working prototype under tight time constraints — earning second place in the process.
slug: ai-hackathon-problem-solving-under-pressure
---

## The Challenge: Define the Problem First

Unlike many projects where the problem is already clearly defined, this AI Hackathon started differently.

We were given limited time and asked to:
- **identify a real-world problem**
- **design an AI-powered solution on the spot**
- and **build a working prototype** within the hackathon window

This immediately shifted the focus from tools to thinking.

Before writing a single line of code, we had to ask:

> *What problem is actually worth solving in the time we have?*

On **16th December 2025**, this approach proved critical, and by the end of the competition our team placed **second overall**.

---

<div align="center">
  <Image
    src="/posts/Hackathon2.jpg"
    width={800}
    height={450}
    alt="AI Hackathon environment and team setup"
  />
</div>

<div align="center">
  <Image
    src="/posts/Hackathon1.jpg"
    width={800}
    height={450}
    alt="Live development and problem-solving during the AI hackathon"
  />
</div>

## The Problem We Chose to Solve

We focused on a problem that was both **relevant** and **realistic**:

> People often have access to data, but struggle to extract clear, actionable insights from it quickly.

In many real-world contexts — education, operations, planning, or decision-making — the challenge is not the lack of data, but **making sense of it under time pressure**.

Our goal was to design a solution that could:
- accept structured or semi-structured data
- surface meaningful insights automatically
- allow users to ask follow-up questions naturally

The emphasis was on **insight generation**, not prediction.

---

## The Solution We Built

Rather than training a machine learning model from scratch, we intentionally designed an **AI-assisted insight system powered by large language models (LLMs)**.

At a high level, the solution:
- accepted user-provided datasets or structured inputs
- used an LLM to analyse patterns, trends, and anomalies
- generated human-readable insights from the data
- exposed a conversational chatbot interface for follow-up prompts and exploration

This approach allowed users to move beyond static summaries and **interactively interrogate their data**.

Importantly, **no model training was performed**.  
The intelligence came from applying existing LLM capabilities to structured data analysis and explanation.

---

<div align="center">
  <Image
    src="/posts/1.png"
    width={800}
    height={450}
    alt="AI-driven data insight generation interface"
  />
</div>

<div align="center">
  <Image
    src="/posts/2.png"
    width={800}
    height={450}
    alt="Conversational AI chatbot used for follow-up data exploration"
  />
</div>

## Who the Solution Was Meant to Help

The system was designed for **non-technical users who still need data-driven clarity**.

That included:
- individuals who need quick insights without writing queries
- decision-makers overwhelmed by raw dashboards
- users who benefit from explanations rather than raw metrics

By focusing on usability and interpretation, we avoided building something impressive-looking but impractical.

---

## Technical Decisions Under Constraint

### Why We Chose an LLM-Based Approach

Given the time constraints, training a custom machine learning model would have:
- required more data than we had
- introduced evaluation complexity
- reduced our ability to deliver a working system

Using an LLM allowed us to:
- move quickly from idea to prototype
- focus on insight quality rather than model tuning
- demonstrate real value within the hackathon window

This reinforced an important lesson: **the right AI approach depends on the problem, not the trend**.

---

### Data Handling and Prompt Design

Without time for extensive preprocessing pipelines, data handling focused on:
- structuring inputs clearly
- removing obvious noise
- designing prompts that guided the LLM toward useful analysis

Prompt design became a core technical task, shaping:
- the type of insights generated
- the level of explanation
- how well the chatbot handled follow-up questions

---

## What Didn’t Work (and Why That Mattered)

Some early ideas were simply too ambitious.

We had to:
- cut features
- simplify workflows
- refocus on the core insight experience

These decisions were uncomfortable but necessary.  
They highlighted how quickly complexity can derail progress when time is limited.

---

## Why We Placed Second

Our **second-place finish** came down to execution and clarity.

The solution:
- addressed a clearly defined problem
- used AI in a meaningful, defensible way
- worked end-to-end
- and could be explained without overcomplicating the narrative

The judges rewarded **practical application and clear value**, not unnecessary technical depth.

---

## What This Experience Taught Me About AI

This hackathon reshaped how I think about AI systems:

- AI does not always mean training models
- LLMs can act as powerful reasoning and insight engines
- Good problem framing matters more than algorithm choice
- Constraints often lead to better design decisions

Most importantly, it reinforced that **AI is most impactful when it helps people think more clearly**, not when it tries to replace them.

---

<div align="center">
  <Image
    src="/posts/certificate.jpg"
    width={800}
    height={450}
    alt="Second place certificate from the AI Hackathon"
  />
</div>

## Closing Thoughts

Being required to define a problem, design an AI-powered solution, and implement it under pressure was one of the most valuable learning experiences I’ve had.

Placing second was rewarding, but the real takeaway was understanding how **AI can be applied responsibly and effectively to real-world decision-making** — especially when time, data, and resources are limited.
